---
title: "Practical 1- Introduction to Soil Statistics"
author: "Maria Anastasiadi"
date: "`r Sys.Date()`"
output: 
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Load packages
```{r}
library(tidyverse)
#library(olsrr)
library(car)
library(ggpubr)
library(rstatix)
library(pwr)
```


# Introduction

Todayâ€™s Practical will focus on exploring soil physicochemical data from Stubton Farm. This dataset consists of measurements of the following soil traits: P, K, Mg (mg/L) and pH in 35 different fields. Each field has been sampled at different locations (between 2-21 locations) and these measurements are considered biological replicates. Also, the measurements have been repeated over three different years: 2016, 2020, 2024, with the exception of a few fields like "Bottom/Top Simons" which has only been sampled in 2020 and 2024. 
Over the course of the next sessions we will use this dataset to a) generate plots and graphs for exploratory data analysis, b) describe the data using descriptive statistics and c) apply appropriate statistical inference methods (t-tests, one-way and repeated measurements ANOVA) to derive statistically valid conclusions. 
The aims of today's session are summarised below: 

## Aims: 

* Perform Quality Control (QC) on the raw data 
* Perform Exploratory Data Analysis 
* Prepare the data for statistical analysis

## Task 1: Quality Control 

The first step before performing any statistical analysis, or even any pre-processing, is to check the content and quality of the data that was given to you. Never assume that the data is correct, complete or accurate!

### Load the Data into the R environment


1. The first step is to empty your workspace 
```{r}
# Clear workspace
rm(list=ls())

# Close figures
graphics.off()
```

2. Then set your working directory by providing the path where the working directory resides

```{r}
#Provide the path to your working directory here (you need to modify the path below)
knitr::opts_knit$set(root.dir ="C:/Users/e102010/OneDrive - Cranfield University/Documents/Bioinformatics_MSc/Teaching/Academic Year 2024-2025/Soils Mastership/Session1_Practicals")
```


3. Import the  data into R

```{r}

soil.data <- read.csv("Data/Stubton_Farm_Soil.csv", sep = ",", header = TRUE, stringsAsFactors = FALSE)
```

4. Check the structure of the dataframe. You can use the function `structure()` from base R or the function `glimpse()` from the `dplyr` package.
```{r}
dplyr::glimpse(soil.data)
```

5. Convert the columns FieldName and Field.ID into factors

```{r}
soil.data <-soil.data %>% mutate_at(c('FieldName', 'Field.ID'), as.factor)
```

Check it worked
```{r}
dplyr::glimpse(soil.data)
```


Let's look at the first 5 rows of the dataset:

```{r, echo=FALSE}
knitr::kable(soil.data[1:5,], caption = "Head of Stubton Farm soil data")
```

### Missing data

Unless you are really lucky, most of the datasets you will work with will have some missing values. This could be due to unavailability of data, a failed experiment, a discarded measurement, or any other unpredictable event leading to no data being produced. In R there can be represented by different values:

* **NA** (Not Assigned)
* "" (an empty value)
* "missing" (or "value too low", or any other string, depending on who produced the data)

Let's verify if our dataset contains any missing values:

```{r}
# is.na() will return a logical matrix with the value "TRUE" for every "NA" in our dataset, and FALSE for any other value.
# table() will then return how any "TRUE" and "FALSE" we have in our matrix.
na_matrix <- is.na(soil.data)
table(na_matrix)
```

Because it is a bit tedious to go through all the entries in the na_matrix we can get the rows with NA values, by using the function `complete.cases()`, which returns only rows which have no missing values.

```{r}
# This will select rows with complete values:
soil_complete <- soil.data[complete.cases(soil.data), ]
# Alternatively we may want to select the rows with missing values. In this case we can use the sympbol "!" which acts as a negation.  So, the next line will select rows with no complete cases:
soil_missing <- soil.data[!complete.cases(soil.data), ]

knitr::kable(soil_missing, caption = "Rows with missing values from the Vanilla dataset")
```

**Note**: We should see 23 out of 939 rows having missing values. For the purposes of today's practical we can decide to remove all the rows with missing values, to simplify the analysis. However, depending on the type of statistical analysis we want to perform, we may need to carefully consider whether removing whole samples (or even years) is going to invalidate the analysis. In the next sessions we will come back to this point. 

### Outliers

Sometimes, we have values out of range. To inspect if this is the case we can create a histogram

```{r}
#Create a histogram for P

hist(soil_complete$P, main = "Histogram of the P concentration", 
     xlab = "P (mg/L)", ylab = "Freq", col = "steelblue")
```
**Question1**: What distribution does the P concentration have?

**Question2**: Which are the most frequent values for the P concentration? 

Answer1: We can see that the distribution is right skewed. 
Answer2: The majority of P values range around 10-15 mg/L.

As you can see by looking at the histogram, there are some extreme concentrations measured for P (60-80 mg/L). To get a better idea we can order the top P values so we can inspect them more closely. 


```{r}
#Order the P soil concentrations in descending order and show the top values:
ordered_P <- soil_complete[order(soil_complete$P, decreasing = TRUE),]

knitr::kable(ordered_P[1:10,], caption = "Highest P concentrations")
```

By looking at the top P values we can see that "North Field" has the highest at 76 mg/L, while "Cow Field" and "Grahams Field" seem to consistently have some of the top P concentrations over different years. Hence, the top value for "North Field" is a suspected outlier since it doesn't seem to be supported by other measurements. Before we rush to remove any suspected "outliers" we can check the range of values for the above fields more specifically by creating a boxplot.  

```{r}

#Create a smaller dataframe with only the North, Cow and Grahams fields. 
Top.fields<- filter(soil_complete, FieldName=="North Field" | FieldName=="Cow Field" | FieldName=="Grahams Field")

#Create a boxplot
Top.fields%>%
ggplot( aes(x=FieldName, y=P, fill=FieldName)) +
    geom_boxplot() +
    geom_jitter(color="black", size=0.4, alpha=0.9) +
    stat_summary(fun = mean,
               geom = "point",
               shape = 18,
               color = "red",
               size = 3) +
    theme_bw() +
    theme(
      legend.position="none",
      plot.title = element_text(size=11)
    ) +
    ggtitle("Top P concentration Fields ") +
    xlab("")
```

By looking at the boxplot it becomes quite obvious that the "North Field" value is an outlier. We can therefore remove it from the dataset. 

```{r}
soil_filtered <- soil_complete[soil_complete$Sample.ID != "S646",]

hist(x = soil_filtered$P, main = "Histogram of the filtered P values", 
    xlab = "P (mg/L)", ylab = "Freq", col = "steelblue")
```


**NOTE** In many cases it will not be obvious straight away which values are outliers; you will need to make a conscious decision on whether to keep or remove them. Fortunately, there are some tests to help you make that decision, such as Grubb's test, Dixon's test and Rosner's test.

Grubb's test will test if the highest value is an outlier. It assumes normality, but as we can see from the histogram above, we can reasonably assume that our data can be approximated by a normal distribution. If we use it on our original dataset, Grubb's test will help us decide which values for P are outlier(s):

```{r}
if(!require('outliers')) install.packages('outliers'); library('outliers')

grubbs.test(soil_complete$P)
```
**Question**: Does the test agree with your decision to remove the "North Field" outlier? 

Answer: Yes


## Task 2. Exploratory Data Analysis


### 2.1 Descriptive Statistics

Before performing any hypothesis testing the first step of the analysis is to perform some exploratory data analysis. 
Let's assume we are interested in the most year of sampling.


1. Create a smaller dataframe by selecting only fields sampled in 2024

```{r}
soil.24 <- dplyr::filter(soil_complete, Year==2024)

ggplot(soil.24, aes(x=P, fill = FieldName)) + 
  geom_histogram(binwidth = 5) +
  labs(x = "P (mg/L)", y = "Freq") +
  ggtitle("Histogram of P (mg/L) in 2024")+
  theme_bw()+
  theme(legend.position="none") #This removes the legend showing the Field Name
```

To make the histogram more interactive we can use the library `plotly`. First save the histogram above as an object; then pass this object as argument to the `ggplotly()` function.
```{r}
library(plotly)

gr<-ggplot(soil.24, aes(x=P, fill = FieldName)) + 
  geom_histogram(binwidth = 5) +
  labs(x = "P (mg/L)", y = "Freq") +
  ggtitle("Histogram of P (mg/L) in 2024")+
  theme_bw()+
  theme(legend.position="none")

ggplotly(gr)
```
Hover over the histogram to see more information regarding each field and counts associated with it per bin. 

**Question**: Is the P concentration normally distributed?


2. Produce descriptive statistics for the dataset.
```{r}
summary(soil.24)
```
**Question:** What can you tell by looking at the descriptive statistics for the different soil traits? Do they look normally distributed?

Answer: All variables, apart from K have Median almost equal to Mean which indicates normal distribution. For K Mean>Median so we expect it to be right skewed. 

4. Create a smaller dataframe with only the soil trait columns:
```{r}
soil.traits <- soil.24[,6:9]
rownames(soil.traits)<-soil.24[,1]

```

5. Use the `sapply()` function to find the mean values for the four variables:
```{r}
soil.mean <- sapply(soil.traits, mean)
round(soil.mean, digits=1)
```

6. Use the `sapply()` function to find the variance and standard deviation values for the soil variables. To calculate variance use the `var` function and for standard deviation the `sd` function:
```{r}
soil.var <-sapply(soil.traits, var)
round(soil.var, digits=1)
```

```{r}
soil.sd <-sapply(soil.traits, sd)
round(soil.sd, digits=1)
```

7. To calculate the RSD, take the ratio of the sd / mean you calculated in the steps earlier:

```{r}
soil.rsd <- soil.sd/soil.mean
round(soil.rsd, digits=2)
```

**Question:** What conclusions can you make from the statistics you calculated above regarding P, K and Mg?

Answer: Although the variance and sd for the K and Mg content look much higher compared to P, the rsd values for all three soil nutrients are much closer, meaning they have a similar degree of variability relative to their respective means.


## Task 3: Hypothesis Testing


## Two-sample t-test 

For this task let us assume we want to compare the P content between two different fields for the same year to see if their means differ. We can randomly select two fields from the dataset provided and apply a two-sample t-test.


**Aim**: Conduct a two-sample t-test to assess the effect of "Field" on the soil P content. 

**Note**:The t-test assumes the following characteristics about the data:<br>

* Independence of the observations. Each subject should belong to only one group.
* No significant outliers in the two groups
* Normality; the data for each group should be approximately normally distributed.
* Homogeneity of variance

The Welch t-test employed by R has the same assumptions except for the Homogeneity of variance. Therefore, we don't need to check for this assumption. <br>
If the normality assumption is not met then we can employ the non-parametric **Mann-Whitney U** test.


1. Create QQ plots for each field to check if the assumption of normality stands.

```{r}
  ggplot(data = soil.24, aes(sample = P)) +    
  geom_qq() +                               
  stat_qq_line() +                          
  facet_wrap(~ Field.ID,                   # Panel by group
             labeller = label_both) +    
  theme_bw()
```
If the points fall approximately along the reference line, for each cell, so we can assume normality of the data.
By looking at this dataset we don't see any obvious violations of normality in the dataset. However, it is obvious that for some fields we only have two observations, which makes it very difficult to make valid statistical analysis. 

2. Now let's select two fields and conduct a two-sample t-test for the P content:
```{r}
ttest1 <-t.test(filter(soil.24, Field.ID==1)$P, filter(soil.24, Field.ID==6)$P)
print(ttest1)
```

To decide whether we can reject the Null Hypothesis in favour of the Alternative $H_{0}$: $Î¼_{1}$ â‰  $Î¼_{2}$, we look at the p-values for the *t(k)* distribution which is an approximation for the two-sample *t*-statistic distribution.


**Question**:By looking at the t-test results can we reject the Null hypothesis?<br><br>

Answer: Yes, as the p value < 0.01

**Exercise**: Repeat the previous process for other pairwise comparisons or soil nutrients:
```{r}
#Example for K:
ttest2 <-t.test(filter(soil.24, Field.ID==1)$K, filter(soil.24, Field.ID==6)$K)
print(ttest2)
```
**Question:** Are the results statistically significant?
Answer: The p value is <0.001 and we can reject the Null hypothesis in favour of the alternative. 


### Calculate the power 1-Î² of the test 

**Power** analysis is an important aspect of experimental design. It allows us to determine the sample size required to detect an effect of a given size with a given degree of confidence. It also allows us to determine the probability of detecting an effect of a given size with a given level of confidence, under sample size constraints. This is very important for determining the sample size when a certain level of power is an essential criterion. 

To perform Power Analysis we employ the following four quantities:

sample size
effect size
significance level Î± = P(Type I error) = probability of finding an effect that is not there
power = 1 - P(Type II error) = probability of finding an effect that is there

Given any three, we can determine the fourth.

The R package 'pwr' can be used to perform power analysis for any type of hypothesis testing. (For more information go to https://www.statmethods.net/stats/power.html)

For the case of the soil data if we wanted to compare two means we could use the 'pwr.t.test()' function to help us determine the minimum number of samples per field to achieve a certain effect and power. 

To find the sample size for the two sample t-test at significance level 0.05, with effect = 0.8 and power 0.7 we can type the following:
```{r}
pwr.t.test(d=0.8,power = 0.7, sig.level=.05,type = "two.sample", alternative="two.sided")
```

where n= the number of samples per group, 
sig.level = the significance level, 
d = the effect size, 
type = the type of t test and takes values "two.sample", "one.sample", "paired".
and alternative = the type of alternative hypothesis and takes values "two.sided", "less", or "greater" to indicate a two-tailed, or one-tailed test. 

**Note**: Specifying an effect size can be quite difficult. In general d values of 0.2, 0.5, and 0.8 can represent small, medium, and large effect sizes respectively.

## One Way Anova

Earlier on we randomly selected pairs of Fields and tested for differences in P concentrations. 
However, this is of limited interest to us if the goal is to test for all different combinations of Fields. Conducting hundreds of t-tests is tedious and increases the chance of Type I errors by finding a significant result by chance alone. (Remember each time we perform t-test at Î±=0.05, we have a 5% chance of observing a significant result if the Null hypothesis was true). 
To mitigate for this problem, we can instead use one-way Anova, which tests the Null Hypothesis that all group means are equal against the Alternative Hypothesis, that at least one mean is different to the others. 

**Aim**: Conduct a One-Way ANOVA to assess the effect of Field on P concentration. 
Run an ANOVA model as follows:
```{r}
soil.24.rm <-filter(soil.24, Field.ID!=15 & Field.ID!=16 & Field.ID!=29) # we remove fields with <2 replicates

#Perform One-way anova for 2024
one.anova <- aov(P ~ FieldName, data = soil.24.rm)
```

## Look at Anova summary. 
Print the ANOVA table for the `one.anova` model using the function `anova()` and passing the ANOVA model name as argument.

```{r}
anova(one.anova)
```

## Check Anova Assumptions. 
Before we report the results for the Anova test, we also need to check that we haven't violated any important assumptions. 

Check the assumptions of normality and equality of variance for the residuals.<br>
1) Are Residuals normally distributed? <br>

### a) QQ plots 
First Create a QQ plot for the residuals.
```{r}
## Draw QQ plot
plot(one.anova, 2)
```

```{r}
shapiro.test(rstandard(one.anova))
```

Note: The QQ plot indicates that the residuals do not follow a normal distribution. To bypass this issue we can select to perform a log transformation of the P values. 
```{r}
# Perform anova on log values for P
one.anova1 <- aov(log(P, base = 10) ~ FieldName, data = soil.24.rm) 
#one.anova1 <- aov(P ~ FieldName, data = soil.24.rm1) 
```

Now check the residuals again
```{r}
anova(one.anova1)
## Draw QQ plot
plot(one.anova1, 2)
```

We can still see some samples with large diviations from normality. We will remove these samples and try anova again
```{r}
soil.24.rm1 <-soil.24.rm[-c(21, 230, 234),] # Also, remove samples with high residuals 

# Then perform anova on log values for P
one.anova2 <- aov(log(P, base = 10) ~ FieldName, data = soil.24.rm1) 
```
Check the residuals 
```{r}
## Draw QQ plot
plot(one.anova2, 2)
```
There is some improvement but we are still not certain the residuals are normally distributed. 

### b) Shapiro-Wilk Normality Test
We can also formally check normality of residuals with the Shapiro-Wilk normality test. The Null Hypothesis is that the residuals are normally distributed. If the p value > 0.05 we cannot reject the Null hypothesis. <br>
To perform the Shapiro-Wilk test we need to get the standardized residuals from the ANOVA model with `rstandard()`, and then use the `shapiro.test()` function to perform the test:
```{r}
shapiro.test(rstandard(one.anova2))
```
**Question**: Are the residuals normally distributed?
Answer: The p value is >0.05, so we can assume normality for the residuals. 

2) Is the Equality of Variation assumption met? <br>

a) First plot the residuals vs fitted 

```{r}
## Draw Fitted values vs Residuals plot
plot(one.anova2, 1)
```

Again, we don't see any deviations from this assumption. To make sure we can apply Levene test. If the p-value is > 0.05, so we can reject the Null hypothesis (residuals not having equal variation). 
```{r}
library(car)
leveneTest(log(P, base=10)~as.factor(Field.ID), data=soil.24.rm1)
```
**Question**: Is the equality of variances assumption met?<br>
Answer: Yes, since p>0.05 we cannot reject the null hypothesis 

 
## Tukey HSD Test 
Aim: Conduct Post-Hoc Tukey Test to see which cultivar pairs have statistically significant differences. <br>

If you are happy that the model assumption have been met, go ahead and conduct pairwise comparisons to determine which cultivars differ in yield.
```{r}
TukeyHSD(one.anova2) 
```
In the Tukey summary table only take into account the pairwise comparisons. 

## Welch One Way Anova

Similar to the Welch t-test we conducted above we can also select a Welch One Way Anova test if the equality of variance criteria is not met. An example is provided below. 

```{r}
library(rstatix)
welch_anova <-welch_anova_test(soil.24.rm1, log(P, base=10) ~ Field.ID)
print(tukey_hsd(soil.24.rm1, log(P, base=10) ~ Field.ID), n=500)

```

## Kruskal Wallis Non parametric test
In case we did not want to apply log transformation or if this did not have the desired effect, then we could choose to perform the Kruskal Wallis Non parametric test, which does not make any assumption about the underlying data. 

```{r}
kruskal.test(P ~ Field.ID, data=soil.24.rm)
```
We can conclude that there are significant differences between the treatment groups because the p-value is less than the significance criterion of 0.05.

As with Anova,we know there is a substantial difference between Fields based on the Kruskal-Wallis testâ€™s results, but we donâ€™t know which pairings of Fields are different in terms of P concentrations.

For Non-parametric statistics we can use the Wilcoxon rank-sum test. For example:
```{r}
pairwise.wilcox.test(soil.24.rm$P, soil.24.rm$Field.ID,
                 p.adjust.method = "BH")
```
You can look at the matrix showing the p adjusted values for all pairwise comparisons to see which Fields are different. 

## Create a barplot for the Anova Results. 
Create a barplot with the mean logP  per Field adding error bars and significant differences.

```{r}
P.mean <- mean(soil.24.data$P) # Total mean
```

```{r}
#Group mean (per Field)
group.mean <- aggregate(wheat.data$Yield, list(wheat.data$Cultivar),  FUN=mean)
colnames(group.mean) <- c("Cultivar", "GM")
```

```{r}
# Calculate sd for each group
group.sd <- aggregate(wheat.data$Yield, list(wheat.data$Cultivar), FUN=sd)
colnames(group.sd) <- c("Cultivar", "GSD")

# convert into se:
group.se <- group.sd$GSD/sqrt(5)
```

```{r}
library("ggsignif")   
ggplot(data = group.mean, 
       aes(x = Cultivar, y = GM, ymin = GM - group.se, ymax = GM + group.se )) + 
  # this adds the means
  geom_col(fill = "skyblue", colour = "skyblue", width = 0.5) +
  # this adds the error bars
  geom_errorbar(width = 0.1, colour = "black", orientation = "x") + 
  # controlling the appearance
  scale_y_continuous(expand = c(0, 0), limits = c(0, 12)) +
  # add labels
  xlab("Cultivar") + ylab("Yield") + 
  geom_signif(comparisons = list(c("KWS-E", "KWS-S"), 
                                 c("KWS-E", "KWS-P"),
                                 c("KWS-P", "KWS-S")),
              map_signif_level = TRUE,
              y_position = c(9.2, 10.5, 11),
              annotations = c("***", "***", "***"),
              size = 0.5,
              textsize = 5) +
  # change theme
  theme_bw()
```

